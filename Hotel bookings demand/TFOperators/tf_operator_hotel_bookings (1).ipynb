{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check that youre using the right TensorFlow image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ZW0jNOFco08",
    "outputId": "5d62c0dd-c14d-45d8-a119-3d289e1a762c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow               2.1.0\n",
      "tensorflow-estimator     2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep tensorflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To package the trainer in a container image, we need a file on the cluster that contains the code as well as a file with the resource definition of the job for the Kubernetes cluster:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINER_FILE = \"tfjob-hotel-demand.py\"\n",
    "KUBERNETES_FILE = \"tfjob-hotel-demand.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We also want to capture output from a cell with %%capture that usually looks like some-resource created. To that end, let's define a helper function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EfHJoFehdrK5"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from IPython.utils.capture import CapturedIO\n",
    "\n",
    "\n",
    "def get_resource(captured_io: CapturedIO) -> str:\n",
    "    \"\"\"\n",
    "    Gets a resource name from `kubectl apply -f <configuration.yaml>`.\n",
    "\n",
    "    :param str captured_io: Output captured by using `%%capture` cell magic\n",
    "    :return: Name of the Kubernetes resource\n",
    "    :rtype: str\n",
    "    :raises Exception: if the resource could not be created\n",
    "    \"\"\"\n",
    "    out = captured_io.stdout\n",
    "    matches = re.search(r\"^(.+)\\s+created\", out)\n",
    "    if matches is not None:\n",
    "        return matches.group(1)\n",
    "    else:\n",
    "        raise Exception(f\"Cannot get resource as its creation failed: {out}. It may already exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "F_x0ISzAeA5w"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_year</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>adults</th>\n",
       "      <th>...</th>\n",
       "      <th>deposit_type</th>\n",
       "      <th>agent</th>\n",
       "      <th>company</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>reservation_status</th>\n",
       "      <th>reservation_status_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>737</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>304.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          hotel  is_canceled  lead_time  arrival_date_year arrival_date_month  \\\n",
       "0  Resort Hotel            0        342               2015               July   \n",
       "1  Resort Hotel            0        737               2015               July   \n",
       "2  Resort Hotel            0          7               2015               July   \n",
       "3  Resort Hotel            0         13               2015               July   \n",
       "4  Resort Hotel            0         14               2015               July   \n",
       "\n",
       "   arrival_date_week_number  arrival_date_day_of_month  \\\n",
       "0                        27                          1   \n",
       "1                        27                          1   \n",
       "2                        27                          1   \n",
       "3                        27                          1   \n",
       "4                        27                          1   \n",
       "\n",
       "   stays_in_weekend_nights  stays_in_week_nights  adults  ...  deposit_type  \\\n",
       "0                        0                     0       2  ...    No Deposit   \n",
       "1                        0                     0       2  ...    No Deposit   \n",
       "2                        0                     1       1  ...    No Deposit   \n",
       "3                        0                     1       1  ...    No Deposit   \n",
       "4                        0                     2       2  ...    No Deposit   \n",
       "\n",
       "   agent company days_in_waiting_list customer_type   adr  \\\n",
       "0    NaN     NaN                    0     Transient   0.0   \n",
       "1    NaN     NaN                    0     Transient   0.0   \n",
       "2    NaN     NaN                    0     Transient  75.0   \n",
       "3  304.0     NaN                    0     Transient  75.0   \n",
       "4  240.0     NaN                    0     Transient  98.0   \n",
       "\n",
       "   required_car_parking_spaces  total_of_special_requests  reservation_status  \\\n",
       "0                            0                          0           Check-Out   \n",
       "1                            0                          0           Check-Out   \n",
       "2                            0                          0           Check-Out   \n",
       "3                            0                          0           Check-Out   \n",
       "4                            0                          1           Check-Out   \n",
       "\n",
       "  reservation_status_date  \n",
       "0              2015-07-01  \n",
       "1              2015-07-01  \n",
       "2              2015-07-02  \n",
       "3              2015-07-02  \n",
       "4              2015-07-03  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as  pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/charlesa101/KubeflowUseCases/draft/Hotel%20bookings%20demand/hotel_bookings.csv?token=AQEY3DFJCQCART4U4QXWS6TA6HBYM\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tlyMqpyJfKGn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tfjob-hotel-demand.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $TRAINER_FILE\n",
    "import argparse\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from numpy.random import seed\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(221)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "def make_datasets_unbatched():\n",
    "  df = pd.read_csv(\"https://raw.githubusercontent.com/charlesa101/KubeflowUseCases/draft/Hotel%20bookings%20demand/hotel_bookings.csv?token=AQEY3DFJCQCART4U4QXWS6TA6HBYM\")\n",
    "  df.head()\n",
    "\n",
    "  # Examine the columns with missing values\n",
    "  df_null = df.isnull().sum()\n",
    "  df_null[df_null.values > 0].sort_values(ascending=False)\n",
    "\n",
    "  # drop missing values\n",
    "  df = df.drop(['company', 'agent'], axis=1)\n",
    "  df = df.dropna(subset=['country', 'children'], axis=0)\n",
    "  df = df.reset_index(drop=True)\n",
    "\n",
    "  # Converting wrong datatype columns to correct type (object to datetime)\n",
    "  df['reservation_status_date'] = pd.to_datetime(df['reservation_status_date'])\n",
    "\n",
    "  # Converting string month to numerical one (Dec = 12, Jan = 1, etc.)\n",
    "  datetime_object = df['arrival_date_month'].str[0:3]\n",
    "  month_number = np.zeros(len(datetime_object))\n",
    "\n",
    "  # Creating a new column based on numerical representation of the months\n",
    "  for i in range(0, len(datetime_object)):\n",
    "    datetime_object[i] = datetime.datetime.strptime(datetime_object[i], \"%b\")\n",
    "    month_number[i] = datetime_object[i].month\n",
    "\n",
    "  # Float to integer conversion\n",
    "  month_number = pd.DataFrame(month_number).astype(int)\n",
    "\n",
    "  # 3 columns merged into one\n",
    "  df['arrival_date'] = df['arrival_date_year'].map(str) + '-' + month_number[0].map(str) + '-' \\\n",
    "                       + df['arrival_date_day_of_month'].map(str)\n",
    "  # Dropping already used columns\n",
    "  df = df.drop(['arrival_date_year', 'arrival_date_month', 'arrival_date_day_of_month',\n",
    "                  'arrival_date_week_number'], axis=1)\n",
    "  # convert the newly created arrival_date feature to datetime type\n",
    "  df['arrival_date'] = pd.to_datetime(df['arrival_date'])\n",
    "\n",
    "  # Calculating total guests by combining adults, children and babies columns\n",
    "  df['total guests'] = df['adults'] + df['children'] + df['babies']\n",
    "\n",
    "  # drop data points that include zero Total Guests\n",
    "  df = df[df['total guests'] != 0]\n",
    "\n",
    "  # Total Number of Days Stayed\n",
    "  df['total stays'] = df['stays_in_weekend_nights'] + df['stays_in_week_nights']\n",
    "\n",
    "  dataNoCancel = df[df['is_canceled'] == 0]\n",
    "  dataNoCancel = dataNoCancel.reset_index(drop=True)\n",
    "\n",
    "  df = df.drop(['adults', 'children', 'babies', 'stays_in_weekend_nights', 'stays_in_week_nights', 'arrival_date', 'reservation_status_date'], axis=1)\n",
    "\n",
    "  # Categorical variables preprocessing with label encoding\n",
    "  list_1 = list(df.columns)\n",
    "  cate_list=[]\n",
    "  for i in list_1:\n",
    "    if df[i].dtype=='object':\n",
    "      cate_list.append(i)\n",
    "  # transform the categorical variables with label encoder\n",
    "  le = LabelEncoder()\n",
    "  for i in cate_list:\n",
    "    df[i] = le.fit_transform(df[i])\n",
    "    \n",
    "  # split the data into dependent variables and independent variable\n",
    "  X = df.drop(['hotel'],axis=1)\n",
    "  y = df.hotel\n",
    "\n",
    "  # split the data into training and test set\n",
    "  X_train,X_test,y_train,y_test = tts(X,y,random_state=36,test_size=0.3)\n",
    "\n",
    "  # scale the data\n",
    "  scaler = StandardScaler()\n",
    "  X_train = scaler.fit_transform(X_train)\n",
    "  X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "  train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "  test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "  train = train_dataset.cache().shuffle(2000).repeat()\n",
    "  return train, test_dataset\n",
    "\n",
    "def model(args):\n",
    "  seed(1)\n",
    "  model = Sequential()\n",
    "  model.add(Dense(10, activation='relu', input_dim=21))\n",
    "  #model.add(BatchNormalization())\n",
    "  model.add(Dense(10, activation='relu'))\n",
    "  #model.add(Dropout(0.2))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "  model.summary()\n",
    "  opt = args.optimizer\n",
    "  model.compile(optimizer=opt,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "  tf.keras.backend.set_value(model.optimizer.learning_rate, args.learning_rate)\n",
    "  return model\n",
    "\n",
    "def main(args):\n",
    "  # MultiWorkerMirroredStrategy creates copies of all variables in the model's\n",
    "  # layers on each device across all workers\n",
    "\n",
    "  strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(\n",
    "  communication=tf.distribute.experimental.CollectiveCommunication.AUTO)\n",
    "  logging.debug(f\"num_replicas_in_sync: {strategy.num_replicas_in_sync}\")\n",
    "  BATCH_SIZE_PER_REPLICA = args.batch_size\n",
    "  BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "    \n",
    "  # Datasets need to be created after instantiation of `MultiWorkerMirroredStrategy`\n",
    "  train_dataset, test_dataset = make_datasets_unbatched()\n",
    "  train_dataset = train_dataset.batch(batch_size=BATCH_SIZE)\n",
    "  test_dataset = test_dataset.batch(batch_size=BATCH_SIZE)\n",
    "\n",
    "  # See: https://www.tensorflow.org/api_docs/python/tf/data/experimental/DistributeOptions\n",
    "  options = tf.data.Options()\n",
    "  options.experimental_distribute.auto_shard_policy = \\\n",
    "  tf.data.experimental.AutoShardPolicy.DATA\n",
    "    \n",
    "  train_datasets_sharded = train_dataset.with_options(options)\n",
    "  test_dataset_sharded = test_dataset.with_options(options)\n",
    "\n",
    "  with strategy.scope():\n",
    "    # Model building/compiling need to be within `strategy.scope()`.\n",
    "    multi_worker_model = model(args)\n",
    "\n",
    "    # Keras' `model.fit()` trains the model with specified number of epochs and\n",
    "    # number of steps per epoch. \n",
    "    multi_worker_model.fit(train_datasets_sharded,\n",
    "                         epochs=100,\n",
    "                         steps_per_epoch=30)\n",
    "\n",
    "    eval_loss, eval_acc = multi_worker_model.evaluate(test_dataset_sharded, \n",
    "                                                    verbose=0, steps=10)\n",
    "    # Log metrics for Katib\n",
    "    logging.info(\"loss={:.4f}\".format(eval_loss))\n",
    "    logging.info(\"accuracy={:.4f}\".format(eval_acc))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument(\"--batch_size\",\n",
    "                      type=int,\n",
    "                      default=32,\n",
    "                      metavar=\"N\",\n",
    "                      help=\"Batch size for training (default: 128)\")\n",
    "  parser.add_argument(\"--learning_rate\", \n",
    "                      type=float,  \n",
    "                      default=0.1,\n",
    "                      metavar=\"N\",\n",
    "                      help='Initial learning rate')\n",
    "  parser.add_argument(\"--optimizer\", \n",
    "                      type=str, \n",
    "                      default='adam',\n",
    "                      metavar=\"N\",\n",
    "                      help='optimizer')\n",
    "  parsed_args, _ = parser.parse_known_args()\n",
    "  main(parsed_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aL20qOQ3sX8D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/device:CPU:0',)\n",
      "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:CPU:0',), communication = CollectiveCommunication.AUTO\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                220       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 341\n",
      "Trainable params: 341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 30 steps\n",
      "Epoch 1/100\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.5494 - accuracy: 0.7406\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7583\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7396\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7854\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7833\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8052\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.8052\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7729\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7740\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7833\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8125\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.8042\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7417\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8125\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.8042\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8208\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8313\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8354\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8302\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8188\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.8135\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8021\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.8229\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8490\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8198\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8510\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8406\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8448\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8323\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8198\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8260\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8385\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8240\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8156\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8281\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8302\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8292\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8365\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8479\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8094\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8615\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8510\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8427\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8562\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8365\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8458\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8458\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8292\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8687\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8313\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3486 - accuracy: 0.8698\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8562\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8260\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8500\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8531\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8604\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8635\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8687\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8677\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8510\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8375\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8469\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8573\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8469\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8448\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8406\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8583\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8469\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8406\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8438\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8656\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8635\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8542\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8740\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8562\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8458\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8438\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8625\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8490\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8448\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8417\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8365\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8531\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8594\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8667\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8479\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8594\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8542\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8448\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8448\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8406\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8531\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8479\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8562\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8542\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8406\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:loss=0.4025\n",
      "INFO:root:accuracy=0.8156\n"
     ]
    }
   ],
   "source": [
    "%run $TRAINER_FILE --optimizer 'adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hQ8A2HYsxjl"
   },
   "source": [
    "**Create a distributed TFJob**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0c90SlDtHNy"
   },
   "source": [
    "For large training jobs, we wish to run our trainer in a distributed mode. Once the notebook server cluster can access the Docker image from the registry, we can launch a distributed TF job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIPcBFF-tTnh"
   },
   "source": [
    "The specification for a distributed TFJob is defined using YAML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Vhv3MRIasaTd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing tfjob-hotel-demand.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $KUBERNETES_FILE\n",
    "apiVersion: \"kubeflow.org/v1\"\n",
    "kind: \"TFJob\"\n",
    "metadata:\n",
    "  name: \"hotel-booking\"\n",
    "  namespace: tolu\n",
    "spec:\n",
    "  cleanPodPolicy: None\n",
    "  tfReplicaSpecs:\n",
    "    Worker:\n",
    "      replicas: 2\n",
    "      restartPolicy: OnFailure\n",
    "      template:\n",
    "        metadata:\n",
    "          annotations:\n",
    "            sidecar.istio.io/inject: \"false\"\n",
    "        spec:\n",
    "          containers:\n",
    "          - name: tensorflow\n",
    "            # modify this property if you would like to use a custom image\n",
    "            image: mavencodev/tf_hotel:v.0.1 # put the correct image\n",
    "            command:\n",
    "                - \"python\"\n",
    "                - \"/tfjob-hotel-demand.py\"\n",
    "                - \"--batch_size=64\"\n",
    "                - \"--learning_rate=0.1\"\n",
    "                - \"--optimizer=adam\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGrkAbxWuga7"
   },
   "source": [
    "**Deploy the distributed training job**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UJRoC9M0uPaB"
   },
   "outputs": [],
   "source": [
    "%%capture tf_output --no-stderr\n",
    "! kubectl create -f $KUBERNETES_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "clKXCyrxurlu"
   },
   "outputs": [],
   "source": [
    "TF_JOB = get_resource(tf_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usQpiT3cuxtD"
   },
   "source": [
    "**Check the job status using the following command**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZecFW3N9usnl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:         hotel-booking\r\n",
      "Namespace:    tolu\r\n",
      "Labels:       <none>\r\n",
      "Annotations:  <none>\r\n",
      "API Version:  kubeflow.org/v1\r\n",
      "Kind:         TFJob\r\n",
      "Metadata:\r\n",
      "  Creation Timestamp:  2021-07-13T13:46:29Z\r\n",
      "  Generation:          1\r\n",
      "  Managed Fields:\r\n",
      "    API Version:  kubeflow.org/v1\r\n",
      "    Fields Type:  FieldsV1\r\n",
      "    fieldsV1:\r\n",
      "      f:spec:\r\n",
      "        .:\r\n",
      "        f:cleanPodPolicy:\r\n",
      "        f:tfReplicaSpecs:\r\n",
      "          .:\r\n",
      "          f:Worker:\r\n",
      "            .:\r\n",
      "            f:replicas:\r\n",
      "            f:restartPolicy:\r\n",
      "            f:template:\r\n",
      "              .:\r\n",
      "              f:metadata:\r\n",
      "                .:\r\n",
      "                f:annotations:\r\n",
      "                  .:\r\n",
      "                  f:sidecar.istio.io/inject:\r\n",
      "              f:spec:\r\n",
      "    Manager:      kubectl\r\n",
      "    Operation:    Update\r\n",
      "    Time:         2021-07-13T13:46:29Z\r\n",
      "    API Version:  kubeflow.org/v1\r\n",
      "    Fields Type:  FieldsV1\r\n",
      "    fieldsV1:\r\n",
      "      f:spec:\r\n",
      "        f:tfReplicaSpecs:\r\n",
      "          f:Worker:\r\n",
      "            f:template:\r\n",
      "              f:metadata:\r\n",
      "                f:creationTimestamp:\r\n",
      "              f:spec:\r\n",
      "                f:containers:\r\n",
      "      f:status:\r\n",
      "        .:\r\n",
      "        f:conditions:\r\n",
      "        f:replicaStatuses:\r\n",
      "          .:\r\n",
      "          f:Worker:\r\n",
      "        f:startTime:\r\n",
      "    Manager:         tf-operator.v1\r\n",
      "    Operation:       Update\r\n",
      "    Time:            2021-07-13T13:46:31Z\r\n",
      "  Resource Version:  1671394\r\n",
      "  Self Link:         /apis/kubeflow.org/v1/namespaces/tolu/tfjobs/hotel-booking\r\n",
      "  UID:               6f4618db-5c8d-4f75-a689-ba82837761a8\r\n",
      "Spec:\r\n",
      "  Clean Pod Policy:  None\r\n",
      "  Tf Replica Specs:\r\n",
      "    Worker:\r\n",
      "      Replicas:        2\r\n",
      "      Restart Policy:  OnFailure\r\n",
      "      Template:\r\n",
      "        Metadata:\r\n",
      "          Annotations:\r\n",
      "            sidecar.istio.io/inject:  false\r\n",
      "        Spec:\r\n",
      "          Containers:\r\n",
      "            Command:\r\n",
      "              python\r\n",
      "              /tfjob-hotel-demand.py\r\n",
      "              --batch_size=64\r\n",
      "              --learning_rate=0.1\r\n",
      "              --optimizer=adam\r\n",
      "            Image:  mavencodev/tf_hotel:v.0.1\r\n",
      "            Name:   tensorflow\r\n",
      "Status:\r\n",
      "  Conditions:\r\n",
      "    Last Transition Time:  2021-07-13T13:46:30Z\r\n",
      "    Last Update Time:      2021-07-13T13:46:30Z\r\n",
      "    Message:               TFJob hotel-booking is created.\r\n",
      "    Reason:                TFJobCreated\r\n",
      "    Status:                True\r\n",
      "    Type:                  Created\r\n",
      "  Replica Statuses:\r\n",
      "    Worker:\r\n",
      "  Start Time:  2021-07-13T13:46:31Z\r\n",
      "Events:\r\n",
      "  Type    Reason                   Age   From         Message\r\n",
      "  ----    ------                   ----  ----         -------\r\n",
      "  Normal  SuccessfulCreatePod      27s   tf-operator  Created pod: hotel-booking-worker-0\r\n",
      "  Normal  SuccessfulCreatePod      26s   tf-operator  Created pod: hotel-booking-worker-1\r\n",
      "  Normal  SuccessfulCreateService  26s   tf-operator  Created service: hotel-booking-worker-0\r\n",
      "  Normal  SuccessfulCreateService  26s   tf-operator  Created service: hotel-booking-worker-1\r\n"
     ]
    }
   ],
   "source": [
    "! kubectl describe $TF_JOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HJsiicldu-OA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                     READY   STATUS              RESTARTS   AGE\r\n",
      "hotel-booking-worker-0   0/1     ContainerCreating   0          61s\r\n",
      "hotel-booking-worker-1   0/1     ContainerCreating   0          60s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods -l job-name=hotel-booking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Ubs-WkzVvFjY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73s         Normal   SuccessfulCreatePod       tfjob/hotel-booking          Created pod: hotel-booking-worker-1\r\n",
      "73s         Normal   Scheduled                 pod/hotel-booking-worker-1   Successfully assigned tolu/hotel-booking-worker-1 to instance-1\r\n",
      "73s         Normal   SuccessfulCreateService   tfjob/hotel-booking          Created service: hotel-booking-worker-1\r\n",
      "72s         Normal   Pulling                   pod/hotel-booking-worker-1   Pulling image \"mavencodev/tf_hotel:v.0.1\"\r\n",
      "6s          Normal   Pulled                    pod/hotel-booking-worker-0   Successfully pulled image \"mavencodev/tf_hotel:v.0.1\"\r\n",
      "5s          Normal   Created                   pod/hotel-booking-worker-1   Created container tensorflow\r\n",
      "5s          Normal   Started                   pod/hotel-booking-worker-1   Started container tensorflow\r\n",
      "5s          Normal   Started                   pod/hotel-booking-worker-0   Started container tensorflow\r\n",
      "5s          Normal   Created                   pod/hotel-booking-worker-0   Created container tensorflow\r\n",
      "5s          Normal   Pulled                    pod/hotel-booking-worker-1   Successfully pulled image \"mavencodev/tf_hotel:v.0.1\"\r\n"
     ]
    }
   ],
   "source": [
    "! kubectl get events --sort-by='.lastTimestamp' | tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "N49H4ks8vJvS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-13 13:47:40.646571: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n",
      "2021-07-13 13:47:40.646622: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n",
      "WARNING:tensorflow:From /tfjob-hotel-demand.py:128: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "use distribute.MultiWorkerMirroredStrategy instead\r\n",
      "2021-07-13 13:47:42.618392: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n",
      "2021-07-13 13:47:42.618748: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n",
      "2021-07-13 13:47:42.618778: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\r\n",
      "2021-07-13 13:47:42.618828: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (hotel-booking-worker-0): /proc/driver/nvidia/version does not exist\r\n",
      "2021-07-13 13:47:42.620606: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n",
      "2021-07-13 13:47:42.622032: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n",
      "2021-07-13 13:47:42.632617: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> hotel-booking-worker-0.tolu.svc:2222, 1 -> hotel-booking-worker-1.tolu.svc:2222}\r\n",
      "2021-07-13 13:47:42.633840: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://hotel-booking-worker-0.tolu.svc:2222\r\n",
      "INFO:tensorflow:Enabled multi-worker collective ops with available devices: ['/job:worker/replica:0/task:0/device:CPU:0']\r\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:0',)\r\n",
      "INFO:tensorflow:Waiting for the cluster, timeout = inf\r\n",
      "INFO:tensorflow:Cluster is ready.\r\n",
      "INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['hotel-booking-worker-0.tolu.svc:2222', 'hotel-booking-worker-1.tolu.svc:2222']}, task_type = 'worker', task_id = 0, num_workers = 2, local_devices = ('/job:worker/task:0',), communication = CommunicationImplementation.AUTO\r\n",
      "2021-07-13 13:47:48.591868: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\n",
      "2021-07-13 13:47:48.592391: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 6 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 6 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 6 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 6 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\r\n",
      "Model: \"sequential\"\r\n",
      "_________________________________________________________________\r\n",
      "Layer (type)                 Output Shape              Param #   \r\n",
      "=================================================================\r\n",
      "dense (Dense)                (None, 10)                220       \r\n",
      "_________________________________________________________________\r\n",
      "dense_1 (Dense)              (None, 10)                110       \r\n",
      "_________________________________________________________________\r\n",
      "dense_2 (Dense)              (None, 1)                 11        \r\n",
      "=================================================================\r\n",
      "Total params: 341\r\n",
      "Trainable params: 341\r\n",
      "Non-trainable params: 0\r\n",
      "_________________________________________________________________\r\n",
      "Epoch 1/100\r\n",
      "30/30 [==============================] - 2s 5ms/step - loss: 0.6075 - accuracy: 0.6758\r\n",
      "Epoch 2/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7743\r\n",
      "Epoch 3/100\r\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.8174\r\n",
      "Epoch 4/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8298\r\n",
      "Epoch 5/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8440\r\n",
      "Epoch 6/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8273\r\n",
      "Epoch 7/100\r\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8258\r\n",
      "Epoch 8/100\r\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8443\r\n",
      "Epoch 9/100\r\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3895 - accuracy: 0.8351\r\n",
      "Epoch 10/100\r\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3738 - accuracy: 0.8560\r\n",
      "Epoch 11/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3486 - accuracy: 0.8551\r\n",
      "Epoch 12/100\r\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3768 - accuracy: 0.8500\r\n",
      "Epoch 13/100\r\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.8331\r\n",
      "Epoch 14/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3394 - accuracy: 0.8633\r\n",
      "Epoch 15/100\r\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3349 - accuracy: 0.8700\r\n",
      "Epoch 16/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3254 - accuracy: 0.8689\r\n",
      "Epoch 17/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3712 - accuracy: 0.8413\r\n",
      "Epoch 18/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3742 - accuracy: 0.8501\r\n",
      "Epoch 19/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3646 - accuracy: 0.8559\r\n",
      "Epoch 20/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8726\r\n",
      "Epoch 21/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.8581\r\n",
      "Epoch 22/100\r\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3375 - accuracy: 0.8644\r\n",
      "Epoch 23/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3487 - accuracy: 0.8568\r\n",
      "Epoch 24/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3692 - accuracy: 0.8494\r\n",
      "Epoch 25/100\r\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3674 - accuracy: 0.8506\r\n",
      "Epoch 26/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8676\r\n",
      "Epoch 27/100\r\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3609 - accuracy: 0.8530\r\n",
      "Epoch 28/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3449 - accuracy: 0.8584\r\n",
      "Epoch 29/100\r\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3339 - accuracy: 0.8671\r\n",
      "Epoch 30/100\r\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3523 - accuracy: 0.8548\r\n",
      "Epoch 31/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3629 - accuracy: 0.8550\r\n",
      "Epoch 32/100\r\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3592 - accuracy: 0.8489\r\n",
      "Epoch 33/100\r\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3501 - accuracy: 0.8537\r\n",
      "Epoch 34/100\r\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3158 - accuracy: 0.8770\r\n",
      "Epoch 35/100\r\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3422 - accuracy: 0.8582\r\n",
      "Epoch 36/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3383 - accuracy: 0.8594\r\n",
      "Epoch 37/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8696\r\n",
      "Epoch 38/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3124 - accuracy: 0.8691\r\n",
      "Epoch 39/100\r\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3253 - accuracy: 0.8735\r\n",
      "Epoch 40/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3397 - accuracy: 0.8652\r\n",
      "Epoch 41/100\r\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3202 - accuracy: 0.8711\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.2989 - accuracy: 0.8755\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3504 - accuracy: 0.8549\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3252 - accuracy: 0.8715\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3150 - accuracy: 0.8743\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3229 - accuracy: 0.8679\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3191 - accuracy: 0.8614\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3104 - accuracy: 0.8742\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8741\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3347 - accuracy: 0.8612\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3342 - accuracy: 0.8699\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3232 - accuracy: 0.8676\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3349 - accuracy: 0.8647\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3426 - accuracy: 0.8577\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3332 - accuracy: 0.8732\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3285 - accuracy: 0.8706\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3152 - accuracy: 0.8653\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.2999 - accuracy: 0.8766\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3031 - accuracy: 0.8807\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3149 - accuracy: 0.8684\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3166 - accuracy: 0.8743\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3193 - accuracy: 0.8746\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8723\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3295 - accuracy: 0.8745\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3180 - accuracy: 0.8727\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3106 - accuracy: 0.8817\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3045 - accuracy: 0.8761\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3129 - accuracy: 0.8693\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3154 - accuracy: 0.8703\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3221 - accuracy: 0.8685\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8674\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3109 - accuracy: 0.8729\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8770\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3188 - accuracy: 0.8764\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3051 - accuracy: 0.8795\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3402 - accuracy: 0.8655\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8650\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3554 - accuracy: 0.8596\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3008 - accuracy: 0.8755\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.2954 - accuracy: 0.8892\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3078 - accuracy: 0.8742\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3244 - accuracy: 0.8733\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3152 - accuracy: 0.8726\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8595\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3235 - accuracy: 0.8709\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3073 - accuracy: 0.8763\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3065 - accuracy: 0.8848\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3028 - accuracy: 0.8862\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3158 - accuracy: 0.8748\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2953 - accuracy: 0.8822\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3191 - accuracy: 0.8696\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3060 - accuracy: 0.8866\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3214 - accuracy: 0.8704\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3360 - accuracy: 0.8611\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3148 - accuracy: 0.8774\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3167 - accuracy: 0.8744\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3185 - accuracy: 0.8726\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3105 - accuracy: 0.8741\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3075 - accuracy: 0.8703\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8605\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, implementation = AUTO, num_packs = 1\n",
      "INFO:root:loss=0.2719\n",
      "INFO:root:accuracy=0.8914\n"
     ]
    }
   ],
   "source": [
    "! kubectl logs -f hotel-booking-worker-0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9t5oqn6Evbta"
   },
   "source": [
    "**Run the following command to delete the job**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "4vj3zRwMvPiY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfjob.kubeflow.org \"hotel-booking\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "#! kubectl delete $TF_JOB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Djo5FdcLvJtc"
   },
   "source": [
    "**Check to see if the pod is still up and running**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (NotFound): pods \"hotel-booking\" not found\r\n"
     ]
    }
   ],
   "source": [
    "#! kubectl -n tolu logs -f hotel-booking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tf-operator hotel-bookings",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
